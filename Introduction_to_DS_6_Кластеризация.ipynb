{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в Data Science\n",
    "## Эпизод 6: Исчезновение учителя\n",
    "\n",
    "\n",
    "Авторы теоретического материала - исследователь СколТеха Сергей Королев и программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий\n",
    "\n",
    "Основное отличие методов обучения без учителя от привычных классификаций и регрессий машинного обучения в том, что разметки для данных в этом случае нет. От этого образуются сразу несколько особенностей — во-первых это возможность использования несопоставимо больших объёмов данных, поскольку их не нужно будет размечать руками для обучения, а во-вторых это неясность измерения качества методов, из-за отсутствия таких же прямолинейных и интуитивно понятных метрик, как в задачах обучения с учителем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных\n",
    "Перед тем, как мы начнем развлекаться, пока учителя нет, давайте, как обычно, поработаем с данными и приведем их к какому-то адекватному виду."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, долгожданные данные по студентам, где мы объединили две группы - БМБ 177 и БМБ 172, если вы еще не знакомы, то начнем знакомиться заочно, а в конце еще и поймем, кто из вас друг на друга похож ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/dataset.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наши с вами переменные:\n",
    "    \n",
    "- Name - попробуйте догадаться, что это\n",
    "- FavouriteSeries - ваши любимые сериалы\n",
    "- StarWars - эпизоды ЗВ в порядке убывания предпочтения\n",
    "- MetroTime - сколько в минутах вы тратите времени на дорогу до универа на метро\n",
    "- ExamScore - суммарный балл ЕГЭ\n",
    "- HomeInternetSpeed - скорость интернета дома\n",
    "\n",
    "Какие переменные непрерывные, а какие категориальные?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на пропущенные значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже, пропусков не так уж и много, давайте поработаем с каждой из переменных:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MetroTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.MetroTime.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже, есть интересное значение справа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.MetroTime.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "172800.0/60/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, кто-то действительно тратит 120 дней своей жизни на поездки на метро, но предположим, что человек все же ошибся и заменим значение на что-то более нейтральное и медианное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.MetroTime[data.MetroTime==data.MetroTime.max()] = data.MetroTime.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.MetroTime.hist(normed=True, bins=10)\n",
    "data.MetroTime.plot.kde()\n",
    "plt.xlim(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заполнение пропусков\n",
    "Если студент не указал время на метро, предположим, что он им и не пользуется, так что заполним пропуски нулями, а заодно создадим переменную - пользуется ли студент метро"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.MetroTime = data.MetroTime.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['UseMetro'] = data.MetroTime != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.UseMetro.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/Star_wars2.svg/1200px-Star_wars2.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.StarWars.hist(bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова предположим, что если что-то пропущено, это значит, что человек не смотрел величайшую космическую сагу и вообще как так можно жить\n",
    "\n",
    "![](https://i.gifer.com/Bme8.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.StarWars.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.StarWars[data.StarWars>0].hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее происходит немного магии и преобразований нашей переменной с перекодированием её в строку, заменой нулей на строку из шести нулей и разбиением одного столбца на шесть отдельных. Также не забываем дропнуть из исходного датасета закодированные переменные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.StarWars = data.StarWars.astype(int).astype(str)\n",
    "data.StarWars = data.StarWars.replace('0', '000000')\n",
    "data.StarWars = data.StarWars.apply(lambda row: [x for x in row])\n",
    "\n",
    "StarWars = pd.DataFrame(data.StarWars.tolist())\n",
    "StarWars.columns = [\"SW_{}\".format(i) for i in range(1, 7)]\n",
    "\n",
    "data.drop(['StarWars'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StarWars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот здесь можно было бы добавить полученные датасет с эпизодами ЗВ в наш исходный датасет, но дальнейшая практика показала, что это слишком уж мощный признак, по которому сразу  студенты делятся на две группы - тех, кто смотрел ЗВ, и тех, кто не смотрел, а это не так интересно для  нашего мини-исследования, поэтому добавлять мы сейчас этот кусок не будем :3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.concat([data, StarWars.astype(int)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExamScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.ytimg.com/vi/inY2_sZCw20/hqdefault.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ExamScore.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ExamScore.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.ExamScore==1337]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Впечатляющий результат! Чуров был бы доволен. Но скорее всего единичка затесалась туда нечаянно, так что уберем лишнюю тысячу баллов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ExamScore[data.ExamScore==data.ExamScore.max()] = 337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "data.ExamScore.hist(normed=True)\n",
    "data.ExamScore.plot.kde();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по равпределению, кто-то сдавал 3 экзамена, кто-то 4, кто-то указал всего 1, так что надо бы это дело привести к чему-то более-менее однородному, давайте сначала посчитаем, сколько человек сдавал экзаменов.\n",
    "\n",
    "Для этого возьмем целый остаток от деления на $100$ и прибавим к нему $1$, если есть нецелый остаток от $100$. Например, если у человека 350 баллов, то первая часть нам даст $350//100 = 3$, а вторая $350%100=50$; $50 > 0 = 1 (True)$; итого $3 + 1 = 4$ экзамена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ExamQuantity'] = data.ExamScore//100 + (data.ExamScore%100 > 0).astype(int)\n",
    "data['ExamQuantity'] = data['ExamQuantity'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ExamQuantity.value_counts().plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь добавим переменную со средним баллом, потому что мы можем, и потому что это круто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['AverageScore'] = data.ExamScore.div(data.ExamQuantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.AverageScore.hist(bins=5, normed=True)\n",
    "data.AverageScore.plot.kde()\n",
    "plt.title(\"Распределение среднего балла ЕГЭ\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем облегченно дропнуть наш изначальный ExamScore, так как у нас появились две новых переменных, его кодирующих. А заодно еще добавим переменную ScoreUnknown, чтобы отслеживать тех, кто ЕГЭ либо не сдавал, либо благополучно успел забыть свой результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['ExamScore'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ScoreUnknown'] = data.AverageScore.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ScoreUnknown.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропущенные значения снова заполним медианами, чтобы они нам не мешались"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.AverageScore = data.AverageScore.fillna(data.AverageScore.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HomeInternetSpeed\n",
    "\n",
    "![](https://i0.wp.com/www.developermemes.com/wp-content/uploads/2015/02/Chrome-Vs-Firefox-While-IE-Eats-Glue.jpg?fit=698%2C501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.HomeInternetSpeed.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодируем слова цифрами, здесь не нужно делать OHE так как мы заведомо предполагаем, что одна категория лучше (больше) другой и можем это передать при помощи циферок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.HomeInternetSpeed = data.HomeInternetSpeed.map({'хорошо':1, \"средне\":0, \"плохо\":-1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова запомним тех, про кого мы не знаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['InternetSpeedUnknown'] = data.HomeInternetSpeed.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И заполним пропуски нулями (категория средне)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.HomeInternetSpeed = data.HomeInternetSpeed.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FavoriteSeries\n",
    "Самое интересное и сложненькое\n",
    "\n",
    "![](https://s3.amazonaws.com/dailybreak_images_prod/4c62fad1-004c-4cf5-8cb1-1b873ea4facb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала - переведем весь текст в нижний регистр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.FavoriteSeries = data.FavoriteSeries.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь заполним все пропуски кодовым словом noseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.FavoriteSeries.fillna('noseries', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь не особо хитрыми манимуляциями сначала разобьем каждую строку по запятой, чтобы  получить отдельные сериалы, а затем те названия сериалов, которые состоят из отдельных слова (рик и морти) склеим друг с другом через нижнее подчеркивание (рик\\_и\\_морти) и опять преобразуем в целую строку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.FavoriteSeries_processed = data.FavoriteSeries.str.split(',')\n",
    "print(data.FavoriteSeries_processed.head())\n",
    "\n",
    "data.FavoriteSeries_processed = data.FavoriteSeries_processed.apply(\n",
    "    lambda row: [x.strip().replace(' ', '_') for x in row])\n",
    "print(data.FavoriteSeries_processed.head())\n",
    "\n",
    "data.FavoriteSeries_processed = data.FavoriteSeries_processed.apply(lambda row: \",\".join(row))\n",
    "print(data.FavoriteSeries_processed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь мы будем считать, кто чего смотрел при помощи CountVectorizer - как он устроен посмотрим на доске"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FavoriteSeries_processed = vectorizer.fit_transform(data.FavoriteSeries_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FavoriteSeries_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не так уж много уникальных сериалов - всего 95, так что можно из разреженной матрицы перейти к датафрему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FavoriteSeries_processed = pd.DataFrame(FavoriteSeries_processed.toarray())\n",
    "FavoriteSeries_processed.columns = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FavoriteSeries_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FavoriteSeries_processed.sum().sort_values(ascending=False).head(10).plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим отдельно топ-10 сериалов, которые смотрит большинство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_ten_series = FavoriteSeries_processed.sum().sort_values(ascending=False).head(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 10))\n",
    "sns.heatmap(FavoriteSeries_processed[top_ten_series].corr('spearman'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим этим топ-10 к датасету и выкинем изначальную переменную, которую мы закодировали"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, FavoriteSeries_processed[top_ten_series]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TotalSeriesWatched'] = FavoriteSeries_processed.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NameLength\n",
    "Напоследок, добавим длину имени в качестве признака и на этом успокоимся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['NameLength'] = data.Name.apply(len)\n",
    "data.set_index(data.Name, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop(['Name', 'FavoriteSeries'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 10))\n",
    "sns.heatmap(data.corr('spearman'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media.collegetimes.com/uploads/2015/03/its-done.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кластеризация\n",
    "\n",
    "Интуитивная постановка задачи кластеризации довольно проста и представляет из себя наше желание сказать: \"Вот тут у меня насыпаны точки. Я вижу, что они сваливаются в какие-то кучки вместе. Было бы круто иметь возможность эти точки относить к кучкам и в случае появления новой точки на плоскости говорить, в какую кучку она падает.\" Из такой постановки видно, что пространства для фантазии получается много, и от этого возникает соответствующее множество алгоритмов решения этой задачи. Перечисленные алгоритмы ни в коем случае не описывают данное множество полностью, но являются примерами самых популярных методов решения задачи кластеризации.\n",
    "\n",
    "\n",
    "<figure><img align=\"center\" src=\"https://habrastorage.org/getpro/habr/post_images/8b9/ae5/586/8b9ae55861f22a2809e8b3a00ef815ad.png\"><figcaption>Примеры работы алгоритмов кластеризации из документации пакета scikit-learn</figcaption></figure>\n",
    "\n",
    "### K-means\n",
    "\n",
    "Алгоритм К-средних, наверное, самый популярный и простой алгоритм кластеризации и очень легко представляется в виде простого псевдокода:\n",
    "1. Выбрать количество кластеров $k$, которое нам кажется оптимальным для наших данных.\n",
    "2. Высыпать случайным образом в пространство наших данных $k$ точек (центроидов).\n",
    "3. Для каждой точки нашего набора данных посчитать, к какому центроиду она ближе.\n",
    "4. Переместить каждый центроид в центр выборки, которую мы отнесли к этому центроиду.\n",
    "5. Повторять последние два шага фиксированное число раз, либо до тех пор пока центроиды не \"сойдутся\" (обычно это значит, что их смещение относительно предыдущего положения не превышает какого-то заранее заданного небольшого значения)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем мы с того, что отшкалируем наши непрерывные переменные, чтобы все они были в одном масштабе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# преобразуем все признаки в числовые\n",
    "X = data.copy()\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X.copy()\n",
    "X_scaled[['MetroTime', 'AverageScore', 'NameLength', 'TotalSeriesWatched']] =\\\n",
    "scaler.fit_transform(X[['MetroTime', 'AverageScore', 'NameLength', 'TotalSeriesWatched']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для разнообразия можем снова посомтреть, как наши многомерные данные выглядят на двумерной плоскости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tsne = TSNE(random_state=17)\n",
    "tsne_representation = tsne.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tsne_representation[:, 0], tsne_representation[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже, что-то разделить явно можно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор числа кластеров для kMeans\n",
    "\n",
    "В отличие от задачи классификации или регресии, в случае кластеризации сложнее выбрать критерий, с помощью которого было бы просто представить задачу кластеризации как задачу оптимизации.\n",
    "В случае kMeans распространен вот такой критерий – сумма квадратов расстояний от точек до центроидов кластеров, к которым они относятся.\n",
    "$$ J(C) = \\sum_{k=1}^K\\sum_{i~\\in~C_k} ||x_i - \\mu_k|| \\rightarrow \\min\\limits_C,$$\n",
    "\n",
    "здесь $C$ – множество кластеров мощности $K$, $\\mu_k$ – центроид кластера $C_k$.\n",
    "\n",
    "Понятно, что здравый смысл в этом есть: мы хотим, чтобы точки распологались кучно возле центров своих кластеров. Но вот незадача: минимум такого фнукционала будет достигаться тогда, когда кластеров столько же, сколько и точек (то есть каждая точка – это кластер из одного элемента).\n",
    "Для решения этого вопроса (выбора числа кластеров) часто пользуются такой эвристикой: выбирают то число кластеров, начиная с которого описанный функционал $ J(C) $ падает \"уже не так быстро\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans       # сама модель\n",
    "from sklearn import metrics              # куда ж мы без метрик\n",
    "from scipy.spatial.distance import cdist # функция для рассчета расстояний между парами точек\n",
    "\n",
    "# будем искать оптимальное k\n",
    "inertia = []\n",
    "for k in range(1, 8):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=1).fit(X_scaled)\n",
    "    inertia.append(np.sqrt(kmeans.inertia_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 8), inertia, marker='s');\n",
    "plt.xlabel('$k$')\n",
    "plt.ylabel('$J(C_k)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, после двух кластеров наш функционал ошибки стал уменьшаться не так быстро"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeanModel = KMeans(n_clusters=2)\n",
    "kmeanModel.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из модели мы можем вытаскивать также и лэйблы классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeanModel.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['clusterLabels'] = kmeanModel.labels_\n",
    "X_scaled['clusterLabels'] = kmeanModel.labels_\n",
    "X.clusterLabels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова можем посмотреть на нашу двумерную репрезентацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(kmeanModel.labels_)\n",
    "\n",
    "plt.scatter(tsne_representation[:, 0], tsne_representation[:, 1], \n",
    "            c=X['clusterLabels'].map({0: 'blue', 1: 'orange'}));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, можем посмотреть, чем, в среднем, отличаются две группы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.groupby('clusterLabels').mean().T.plot.barh(figsize=(8, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled[['clusterLabels']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Агломеративная или иерархическая кластеризация\n",
    "\n",
    "Наверное самый простой и понятный алгоритм кластеризации без фиксированного числа кластеров — агломеративная кластеризация. Интуиция у алгоритма очень простая: \n",
    "1. Начинаем с того, что высыпаем на каждую точку свой кластер\n",
    "2. Сортируем попарные расстояния между центрами кластеров по возрастанию\n",
    "3. Берём пару ближайших кластеров, склеиваем их в один и пересчитываем центр кластера\n",
    "4. Повторяем п. 2 и 3 до тех пор, пока все данные не склеятся в один кластер\n",
    "\n",
    "По итогам выполнения такого алгоритма можно построить замечательное дерево склеивания кластеров и глядя на него определить, на каком этапе нам было бы оптимальнее всего остановить алгоритм. Либо воспользоваться тем же правилом локтя, что и в k-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "distance_mat = pdist(X_scaled) # pdist посчитает нам верхний треугольник матрицы попарных расстояний\n",
    "\n",
    "Z = hierarchy.linkage(distance_mat, 'single') # linkage — реализация агломеративного алгоритма\n",
    "plt.figure(figsize=(10, 20))\n",
    "dn = hierarchy.dendrogram(Z, color_threshold=2.1, labels=X.index,leaf_font_size=12., orientation='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.gifer.com/7CXm.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://i0.kym-cdn.com/photos/images/newsfeed/000/707/322/fac.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
